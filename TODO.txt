**** sep w4
= create llama2 endpoint
= support pygmalion & llama2 syntax
= aws cut cost in half

**** sep w3
= client
  = client multi-persona support
  = doesn't crash with endpoint offline
  = support custom persona URL
= server
  = endpoint multi-persona support
  = better interaction logging for retraining

**** sep w1
= new instances added
= everything running on CUDA
= to_bettermodel() working
= inference working like Yuki Bot